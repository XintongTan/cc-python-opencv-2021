{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Featuring...\n",
    "\n",
    "## Feature Detection with Open CV\n",
    "\n",
    "From yesterday, we now know how image processing techniques can go transform an image from one thing into another. More importantly, we've seen how OpenCV itself handles this process. To get more into complex detection in OpenCV we will need a little more than changing pixels and converting images though. How do we go from just seeing edges to things like seeing corners or shapes? What about recognizing movement? For those, we need ways of determining how much of a change is made when we read an image, we need ways of modifying our processing behavior on a per pixel basis, we need so much more.\n",
    "\n",
    "How much more complex can we go? Very. \n",
    "\n",
    "![https://docs.opencv.org/master/sift_keypoints.jpg](img/sift_keypoints.jpg)\n",
    "\n",
    "Welcome to algorithmic world of feature detection.\n",
    "\n",
    "Here we are go far beyond using one or two series of computations to transform our images. We have to start mixing methods, and using our transformations to determine information about the images themselves.This is described in series of alorithms, layered upon one another. A lot of this is the world of computer science. But we will take you through the basics so that you know the general concpets behind feature detection algorithms, how one of them might function, and an overview of several that are made available to you through OpenCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt  #image plotting\n",
    "%matplotlib inline\n",
    "import os #For interacting with Operating System - we use it for going through files\n",
    "import glob #For file name pattern matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What on earth is a corner?\n",
    "\n",
    "No really. What is a corner?\n",
    "\n",
    "How do you imagine a corner vs an edge? What exactly lets us know that a corner is... what it is?\n",
    "\n",
    "![https://docs.opencv.org/master/df/d54/tutorial_py_features_meaning.html](img/feature_building.jpg)\n",
    "\n",
    "Looking at the above photo we can see the types of potential features that exist. But we need a way of describing them.\n",
    "\n",
    "There is the A) the sky, B) wall texture, c) roof edge, D) another roof edge, and then E) and F) two corners. But how are these corners truly defined? Do they need to be this big? Can they be smaller or larger?  Which part of the image is the corner, or is it the whole thing?\n",
    "\n",
    "Consider the following image\n",
    "\n",
    "![person holding android phone in their hand](img/essential-phone-10.jpg)\n",
    "\n",
    "The phone definitely has a _corner_, but maybe not as we would define it above. We have rounded edges and soft points. The natural world is full of things like this. Does the algorithm we devise have the ability to handle this?\n",
    "\n",
    "This is an ongoing problem. We will see how scientists and algorithm designers have tackled it in the past.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing the odds with histograms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out a nice feature of images with pixel data is that they can be nicely binned into histograms. We can use those histograms, generated with kernels to determine, probabilistically what is inside of an image.\n",
    "\n",
    "https://docs.opencv.org/master/d1/db7/tutorial_py_histogram_begins.html\n",
    "\n",
    "These let us take all the pixels in a set and calculate which values of the pixels are the most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken roughly directly from the linked example\n",
    "#this is demonstrated to show the basics of the process\n",
    "img = cv.imread('img/not_a_pipe.jpg')\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB);\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "plt.hist(img.ravel(),256,[0,256]); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Harris Corner Operation\n",
    "\n",
    "Designed by Chris Harris and Mike Stephens\n",
    "https://docs.opencv.org/master/dc/d0d/tutorial_py_features_harris.html\n",
    "\n",
    "In very simple terms, this algorithm applies a sobel filter and then performs a histogram frequency counting operation. Depending on the values of that histogram, we determine if a pixel is past a threshold and worth keeping as a Corner feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the linked example\n",
    "\n",
    "filename = 'img//not_a_pipe.jpg'\n",
    "img = cv.imread(filename)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "#harris takes multiple parameters, Image name, block size (neighborhood), ksize (for sobel), and then k, a constsance\n",
    "\n",
    "dst = cv.cornerHarris(gray,2,3,0.04)\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv.dilate(dst,None)\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "cv.imshow('dst',img)\n",
    "\n",
    "\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print(\"note that it identifies mostly the lettering as corners and basically nothing on the pipe itself\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upgrades, people. Upgrades\n",
    "\n",
    "We can do much, much more than the Harris operation.\n",
    "\n",
    "The Scalar Invariant Feature Transform (SIFT) operation\n",
    "https://docs.opencv.org/master/da/df5/tutorial_py_sift_intro.html\n",
    "\n",
    "Harris did one through a pretty simple set of pathways. SIFT is here to do multiple. \n",
    "\n",
    "![SIFT explainer image](img/sift_explanation.jpg)\n",
    "\n",
    "It is explained pretty well in the link above. But for brevity's sake, this algorithm does a similar operation to Harris, but Gaussian distributed instead of a simple neighborhood check, and also compares against several scales of the image to determine where a pixel might have a corner within it. If that doesn't make sense that's ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#built in feature\n",
    "\n",
    "img = cv.imread('img/not_a_pipe.jpg')\n",
    "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "sift = cv.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    "img=cv.drawKeypoints(gray,kp,img)\n",
    "cv.imwrite('img/img_keypoints.jpg',img)\n",
    "\n",
    "completedImage = cv.imread('img/img_keypoints.jpg', cv.COLOR_BGR2RGB);\n",
    "imgplot = plt.imshow(completedImage)\n",
    "plt.show()\n",
    "\n",
    "print(\"Loook at how it captures far more detail about the potential corners in this image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Open\" Computer Vision with ORB\n",
    "\n",
    "Algorithms and who they come from are vital to know. If this is your first encounter with sophisticated, layered processing techniques, you might be surprised to know that the SIFT algorithm is patented. You can't use it in your own software without paying for it.\n",
    "\n",
    "The people behind the OpenCV library devised their own feature algorithm with ORB. This one is free, so you're good to go for your own projects using this algorithm!\n",
    "\n",
    "https://docs.opencv.org/master/d1/d89/tutorial_py_orb.html\n",
    "\n",
    "Designed by Ethan Rublee, Vincent Rabaud, Kurt Konolige and Gary R. Bradski. This is a prime example of the importance of knowing whose algorithms you are are using and whose perspectives you inject into your code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the example\n",
    "\n",
    "img = cv.imread('img/not_a_pipe.jpg',0)\n",
    "# Initiate ORB detector\n",
    "orb = cv.ORB_create()\n",
    "# find the keypoints with ORB\n",
    "kp = orb.detect(img,None)\n",
    "# compute the descriptors with ORB\n",
    "kp, des = orb.compute(img, kp)\n",
    "# draw only keypoints location,not size and orientation\n",
    "img2 = cv.drawKeypoints(img, kp, None, color=(0,255,0), flags=0)\n",
    "plt.imshow(img2), plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We have only scratched the surface of feature detection here. We could spend hours on implementation details, speculation about feature recognition, alternative image forms, and more, but there would be no way for us to fit that all into this workshop. \n",
    "\n",
    "Feature detection is an ongoing area of research, filled with opportunity for enterprising computational designers to make their mark. \n",
    "\n",
    "Remember that these algorithms are designed by people! They bear the marks of what a person thought about imagery. Those ideas might be durable and they might not be. Sometimes they get patented and stay that way for a long time. Sometimes a fast and free alternative is devised. Technologies change, Images change. Some algorithms perform better than others for certain purposes, some are completely beat by others. \n",
    "\n",
    "Algorithms are design, and now you know a little more about how to navigate them through your own work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
